<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>TREMA @ UNH - index</title>
    <link rel="stylesheet" type="text/css" href="../css/default.css" />
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  </head>
  <body>
    <div id="container">
      <div id="content">
        <div id="sidebar">
          <nav>
            <h1>Navigation</h1>
            <ul>
              <li><a href="../">Home</a></li>
              <li><a href="../wikimarks">Wikimarks</a></li>
            </ul>
          </nav>
        </div>

        <section id="main">
        <h1 id="wikimarks">Wikimarks</h1>
<p>We provide a methodology and tool-set for harvesting relevance benchmarks for a variety of tasks from Wikipedia. We call these benchmarks <em>Wikimarks</em>. This work is an extension of the infrastructure developed while organizing the <a href="http://trec-car.cs.unh.edu/">Complex Answer Retrieval track</a> at <a href="https://trec.nist.gov/">NIST TREC</a> and examines several using Wikipedia to assess several tasks not previously considered in the TREC-CAR context.</p>
<p>We believe that Wikimarks can serve to complement traditional information retrieval benchmarks as they build upon a readily-available source of real-world text content. Furthermore, Wikipedia articles feature exhibit considerable machine-readable structure in the form of page structure, hyperlink structure, and complementary data sources such as <a href="https://wikidata.org/">Wikidata</a>.</p>
<h2 id="tasks">Tasks</h2>
<p>The paper describes Wikimarks for four information retrieval tasks:</p>
<ul>
<li><em>passage retrieval</em>: retrieval of relevant text passages for a keyword query</li>
<li><em>entity retrieval</em>: retrieval of relevant <em>entities</em> (defined to be Wikipedia pages) for a keyword query</li>
<li><em>query-specific clustering</em>: sub-topic clustering of passages for a keyword query</li>
<li><em>query-specific entity-linking</em>: annotation of query-relevant entity links in relevant passages</li>
</ul>
<h2 id="tools-installation-and-usage">Tools, Installation, and Usage</h2>
<p>Our pipeline for generating Wikimarks is found in the <a href="https://github.com/TREMA-UNH/trec-car-release"><code>TREMA-UNH/trec-car-release</code></a> project. Please follow installation, configuration and usage instructions in the <code>README</code>.</p>
<p>This pipeline builds upon the conversion tools provided by the <a href="https://github.com/TREMA-UNH/trec-car-create"><code>trec-car-create</code></a> package, which provides utilities for converting, extracting, inspecting, filtering, and generating benchmarks from Wikipedia. Please follow installation and compilation instructions described in the <code>README</code>.</p>
<h2 id="provided-conversions">Provided Conversions</h2>
<p>Along with the methodology and tools, we provide the raw products of our article conversion pipeline run on the English, Simple English, and Japanese Wikipedia dumps from 1 January 2022. These <code>unprocessedAll</code> datasets include all pages of each Wiki in machine-readable JSONL or CBOR formats.</p>
<ul>
<li><p>English <code>en</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Simple English <code>simple</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Japanese <code>ja</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionCbor.tar.xz">CBOR</a></p></li>
</ul>
<h2 id="provided-benchmarks">Provided Benchmarks</h2>
<p>In addition to the raw conversions described above, we also provide several Wikimarks extracted from these conversions:</p>
<ul>
<li><p>the <code>benchmarks</code> dataset provides Wikimarks for passage retrieval, entity retrieval, query-specific clustering, and entity linking, extracted from the page subsets described in below.</p></li>
<li><p>the <code>unprocessedAllButBenchmark</code> dataset provides all pages except for the set included in <code>benchmarks</code> and is intended to be used for training of systems to be evaluated using <code>benchmarks</code>.</p></li>
<li><p>the <code>paragraphCorpus</code> dataset is a corpus of paragraphs from articles to be used for passage retrieval evaluation.</p></li>
</ul>
<p>These datasets are are provided in JSONL or CBOR formats.</p>
<ul>
<li><p>English <code>en</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Simple English <code>simple</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Japanese <code>ja</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionCbor.tar.xz">CBOR</a></p></li>
</ul>
<h3 id="page-subsets">Page subsets</h3>
<p>The benchmarks are constructed from the following subset of Wikipedia pages from each of the provided Wikipedias:</p>
<dl>
<dt>Vital-articles:</dt>
<dd><p>A set of important articles that the Wikipedia community <a href="https://en.wikipedia.org/wiki/Wikipedia:Vital_articles">identified</a>. The community strives to provide these articles for all languages. We obtain the set of “vital” articles via Wikidata, then filter the processed articles by Wikidata QID.<br />
Predicate: <code>qid-set-from-file "./vital-articles.qids"</code></p>
</dd>
<dt>Good-articles:</dt>
<dd><p>A Wikipedia committee defines a set of <a href="https://en.wikipedia.org/wiki/Wikipedia:Good_articles">good articles</a> that are well-written, contain factually accurate and verifiable information and are of broad importance. Such pages are identified either as template “GA” or “good article”, which our pipeline is configured to expose as page tag “Good article”.<br />
Predicate: <code>has-page-tag ["Good article"]</code></p>
</dd>
<dt>US-history:</dt>
<dd><p>A set of pages in categories that contain the words “United” “States” “history”, such as “History of the United States” or “United States history timelines”.<br />
Predicate: <code>(category-contains "history" &amp; category-contains "united" &amp; category-contains "states")</code></p>
</dd>
<dt>Horseshoe-crab:</dt>
<dd><p>The single Wikipedia page on horseshoe crabs used in the example above. It is identified by its Wikidata QID.<br />
Predicate: <code>qid-in-set ["Q1329239"]</code></p>
</dd>
</dl>
<div id="tab:data-stats">
<table>
<caption>Number of articles in each <em>Wikimark</em> subset.<span id="tab:data-stats" label="tab:data-stats">[tab:data-stats]</span></caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">en</th>
<th style="text-align: right;">simple</th>
<th style="text-align: right;">ja</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>vital-articles.test</td>
<td style="text-align: right;">521</td>
<td style="text-align: right;">461</td>
<td style="text-align: right;">503</td>
</tr>
<tr class="even">
<td>vital-articles.train</td>
<td style="text-align: right;">528</td>
<td style="text-align: right;">471</td>
<td style="text-align: right;">539</td>
</tr>
<tr class="odd">
<td>good-articles.test</td>
<td style="text-align: right;">17,086</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">809</td>
</tr>
<tr class="even">
<td>good-articles.train</td>
<td style="text-align: right;">17,361</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">838</td>
</tr>
<tr class="odd">
<td>US-history.test</td>
<td style="text-align: right;">4,232</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">--</td>
</tr>
<tr class="even">
<td>US-history.train</td>
<td style="text-align: right;">4,284</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">--</td>
</tr>
<tr class="odd">
<td>horseshoe-crab.train</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">--</td>
</tr>
<tr class="even">
<td>benchmarkY1.test</td>
<td style="text-align: right;">131</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">71</td>
</tr>
<tr class="odd">
<td>benchmarkY1.train</td>
<td style="text-align: right;">117</td>
<td style="text-align: right;">42</td>
<td style="text-align: right;">81</td>
</tr>
<tr class="even">
<td>car-train-large.train</td>
<td style="text-align: right;">884,709</td>
<td style="text-align: right;">17,335</td>
<td style="text-align: right;">246,649</td>
</tr>
<tr class="odd">
<td>test200.test</td>
<td style="text-align: right;">--</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">42</td>
</tr>
<tr class="even">
<td>test200.train</td>
<td style="text-align: right;">188</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">44</td>
</tr>
</tbody>
</table>
</div>
<h2 id="license">License</h2>
<p>The conversions and benchmarks described above are licensed under the <a href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>
        </section>
      </div>
    </div>
  </body>
</html>

