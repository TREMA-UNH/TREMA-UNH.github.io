<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>TREMA @ UNH - index</title>
    <link rel="stylesheet" type="text/css" href="../css/default.css" />
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  </head>
  <body>
    <div id="container">
      <div id="content">
        <div id="sidebar">
          <nav>
            <h1>Navigation</h1>
            <ul>
              <li><a href="../">Home</a></li>
              <li><a href="../wikimarks">Wikimarks</a></li>
            </ul>
          </nav>
        </div>

        <section id="main">
        <h1 id="wikimarks">Wikimarks</h1>
<p>We provide a methodology and tool-set for harvesting relevance benchmarks for a variety of tasks from Wikipedia. We call these benchmarks <em>Wikimarks</em>. This work is an extension of the infrastructure developed while organizing the <a href="http://trec-car.cs.unh.edu/">Complex Answer Retrieval track</a> at <a href="https://trec.nist.gov/">NIST TREC</a> and examines several using Wikipedia to assess several tasks not previously considered in the TREC-CAR context.</p>
<p>We believe that Wikimarks can serve to complement traditional information retrieval benchmarks as they build upon a readily-available source of real-world text content. Furthermore, Wikipedia articles feature exhibit considerable machine-readable structure in the form of page structure, hyperlink structure, and complementary data sources such as <a href="https://wikidata.org/">Wikidata</a>.</p>
<h2 id="tasks">Tasks</h2>
<p>The paper describes Wikimarks for four information retrieval tasks:</p>
<ul>
<li><em>passage retrieval</em>: retrieval of relevant text passages for a keyword query</li>
<li><em>entity retrieval</em>: retrieval of relevant <em>entities</em> (defined to be Wikipedia pages) for a keyword query</li>
<li><em>query-specific clustering</em>: sub-topic clustering of passages for a keyword query</li>
<li><em>query-specific entity-linking</em>: annotation of query-relevant entity links in relevant passages</li>
</ul>
<h2 id="tools-installation-and-usage">Tools, Installation, and Usage</h2>
<p>Our pipeline for generating Wikimarks is found in the <a href="https://github.com/TREMA-UNH/trec-car-release"><code>TREMA-UNH/trec-car-release</code></a> project. Please follow installation, configuration and usage instructions in the <code>README</code>.</p>
<p>This pipeline builds upon the conversion tools provided by the <a href="https://github.com/TREMA-UNH/trec-car-create"><code>trec-car-create</code></a> package, which provides utilities for converting, extracting, inspecting, filtering, and generating benchmarks from Wikipedia. Please follow installation and compilation instructions described in the <code>README</code>.</p>
<h2 id="provided-conversions">Provided Conversions</h2>
<p>Along with the methodology and tools, we provide the raw products of our article conversion pipeline run on the English, Simple English, and Japanese Wikipedia dumps from 1 January 2022. These <code>unprocessedAll</code> datasets include all pages of each Wiki in machine-readable JSONL or CBOR formats.</p>
<ul>
<li><p>English <code>en</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Simple English <code>simple</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Japanese <code>ja</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionCbor.tar.xz">CBOR</a></p></li>
</ul>
<h2 id="provided-benchmarks">Provided Benchmarks</h2>
<p>In addition to the raw conversions described above, we also provide several Wikimarks extracted from these conversions:</p>
<ul>
<li><p>the <code>benchmarks</code> dataset provides Wikimarks for passage retrieval, entity retrieval, query-specific clustering, and entity linking, extracted from the page subsets described in below.</p></li>
<li><p>the <code>unprocessedAllButBenchmark</code> dataset provides all pages except for the set included in <code>benchmarks</code> and is intended to be used for training of systems to be evaluated using <code>benchmarks</code>.</p></li>
<li><p>the <code>paragraphCorpus</code> dataset is a corpus of paragraphs from articles to be used for passage retrieval evaluation.</p></li>
</ul>
<p>These datasets are are provided in JSONL or CBOR formats.</p>
<ul>
<li><p>English <code>en</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-en-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Simple English <code>simple</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-simple-collectionCbor.tar.xz">CBOR</a></p></li>
<li><p>Japanese <code>ja</code>: <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionJsonl.tar">JSONL</a> / <a href="http://trec-car.cs.unh.edu/wikimarks/datareleases/wikimarks-20220101/wiki2022-ja-collectionCbor.tar.xz">CBOR</a></p></li>
</ul>
<h3 id="page-subsets">Page subsets</h3>
<p>The benchmarks are constructed from the following subset of Wikipedia pages from each of the provided Wikipedias:</p>
<dl>
<dt>Vital-articles:</dt>
<dd><p>A set of important articles that the Wikipedia community <a href="https://en.wikipedia.org/wiki/Wikipedia:Vital_articles">identified</a>. The community strives to provide these articles for all languages. We obtain the set of “vital” articles via Wikidata, then filter the processed articles by Wikidata QID.<br />
Predicate: <code>qid-set-from-file "./vital-articles.qids"</code></p>
</dd>
<dt>Good-articles:</dt>
<dd><p>A Wikipedia committee defines a set of <a href="https://en.wikipedia.org/wiki/Wikipedia:Good_articles">good articles</a> that are well-written, contain factually accurate and verifiable information and are of broad importance. Such pages are identified either as template “GA” or “good article”, which our pipeline is configured to expose as page tag “Good article”.<br />
Predicate: <code>has-page-tag ["Good article"]</code></p>
</dd>
<dt>US-history:</dt>
<dd><p>A set of pages in categories that contain the words “United” “States” “history”, such as “History of the United States” or “United States history timelines”.<br />
Predicate: <code>(category-contains "history" &amp; category-contains "united" &amp; category-contains "states")</code></p>
</dd>
<dt>Horseshoe-crab:</dt>
<dd><p>The single Wikipedia page on horseshoe crabs used in the example above. It is identified by its Wikidata QID.<br />
Predicate: <code>qid-in-set ["Q1329239"]</code></p>
</dd>
</dl>
<div id="tab:data-stats">
<table>
<caption>Number of articles in each <em>Wikimark</em> subset.<span id="tab:data-stats" label="tab:data-stats">[tab:data-stats]</span></caption>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">en</th>
<th style="text-align: right;">simple</th>
<th style="text-align: right;">ja</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>vital-articles.test</td>
<td style="text-align: right;">521</td>
<td style="text-align: right;">461</td>
<td style="text-align: right;">503</td>
</tr>
<tr class="even">
<td>vital-articles.train</td>
<td style="text-align: right;">528</td>
<td style="text-align: right;">471</td>
<td style="text-align: right;">539</td>
</tr>
<tr class="odd">
<td>good-articles.test</td>
<td style="text-align: right;">17,086</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">809</td>
</tr>
<tr class="even">
<td>good-articles.train</td>
<td style="text-align: right;">17,361</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">838</td>
</tr>
<tr class="odd">
<td>US-history.test</td>
<td style="text-align: right;">4,232</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">--</td>
</tr>
<tr class="even">
<td>US-history.train</td>
<td style="text-align: right;">4,284</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">--</td>
</tr>
<tr class="odd">
<td>horseshoe-crab.train</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">--</td>
</tr>
<tr class="even">
<td>benchmarkY1.test</td>
<td style="text-align: right;">131</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">71</td>
</tr>
<tr class="odd">
<td>benchmarkY1.train</td>
<td style="text-align: right;">117</td>
<td style="text-align: right;">42</td>
<td style="text-align: right;">81</td>
</tr>
<tr class="even">
<td>car-train-large.train</td>
<td style="text-align: right;">884,709</td>
<td style="text-align: right;">17,335</td>
<td style="text-align: right;">246,649</td>
</tr>
<tr class="odd">
<td>test200.test</td>
<td style="text-align: right;">--</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">42</td>
</tr>
<tr class="even">
<td>test200.train</td>
<td style="text-align: right;">188</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">44</td>
</tr>
</tbody>
</table>
</div>
<h2 id="wikimarks-1">Wikimarks</h2>
<p><em>Wikimarks</em> are created from a subset of pages, such as lists of Wikidata QIDs or category memberships. The page subset is separated into a test set and five train folds. For each of them task-specific datasets, such as queries, candidate sets, and relevance ground truth’s for the <em>Wikimarks</em> are exported. By default the following information is provided for each dataset:[^9]</p>
<dl>
<dt>Articles <span class="math inline">†</span>:</dt>
<dd><p>Content of processed articles (JSONL or CBOR).</p>
</dd>
<dt>Titles/QIDs:</dt>
<dd><p>Page titles and Wikidata QIDs of pages in this subset.</p>
</dd>
<dt>Paragraphs <span class="math inline">†</span>:</dt>
<dd><p>Corpus of paragraphs from this article subset.</p>
</dd>
<dt>Provenance:</dt>
<dd><p>Information about the Wikipedia dump the subset originated from.</p>
</dd>
</dl>
<p>Additionally, task-specific <em>Wikimark</em> data is provides as described in the following.</p>
<figure>
<img src="rel-cluster-benchmark.png" alt="Wikimarks derived for article-level retrieval and clustering (left) from a given article (right). Paragraph IDs indicated by numbers in black dots; entity IDs as letters in stick figures; ground truth cluster indexes." /><figcaption aria-hidden="true"><em>Wikimarks</em> derived for article-level retrieval and clustering (left) from a given article (right). Paragraph IDs indicated by numbers in black dots; entity IDs as letters in stick figures; ground truth cluster indexes.</figcaption>
</figure>
<h2 id="retrieval-wikimark">Retrieval <em>Wikimark</em></h2>
<p>The retrieval <em>Wikimark</em> is designed to study the quality of retrieval models. For queries derived from Wikipedia titles, any paragraph originating from the Wikipedia article is counted as relevant. This <em>Wikimark</em> was referred to as the “automatic ground truth” in the TREC Complex Answer Retrieval task.</p>
<p><em>Wikimarks</em> for three kinds of retrieval scenarios are provided:</p>
<ul>
<li><p>Article: The query is the page title, and the goal is to retrieve paragraphs that are relevant for this query. For the passage retrieval relevance data (i.e., qrels) any paragraph located anywhere on the original page is counted as relevant, all other paragraphs are non-relevant.</p></li>
<li><p>Toplevel: The query is a combination of page title and heading of a top-level section. The goal is to retrieve paragraphs that are in fact located within this section or one of its subsections.</p></li>
<li><p>Hierarchical: The query is derived from any section on the page. The goal is to retrieve paragraphs that are exactly in this section, not a subsection.</p></li>
</ul>
<p>In addition to passage-level retrieval, we also provide a <em>Wikimark</em> for entity retrieval, where any entity (as represented by their Wikipedia pages) that is linked to from a relevant paragraph is regarded as relevant.</p>
<p>As a corpus for retrieving passages from, we recommend to use the paragraph corpus described in Section <a href="#sec:paragraph-corpus" data-reference-type="ref" data-reference="sec:paragraph-corpus">[sec:paragraph-corpus]</a>. As a legal set of entities, we recommend to use an unprocessed dump of Wikipedia pages.</p>
<p>For the retrieval <em>Wikimark</em>, we provide the following information:</p>
<dl>
<dt>Outlines:</dt>
<dd><p>Title and section outlines of the articles, to derive query texts from. Page metadata is available.</p>
</dd>
<dt>Topics:</dt>
<dd><p>Query IDs for each section—these can also be obtained from the outlines.</p>
</dd>
<dt>Passage Qrels <span class="math inline">†</span>:</dt>
<dd><p><code>Trec-eval</code> compatible qrels files of paragraph IDs for article-level retrieval, top-level section retrieval, and hierarchical section retrieval.</p>
</dd>
<dt>Entity Qrels <span class="math inline">†</span>:</dt>
<dd><p><code>Trec-eval</code> compatible qrels files of entity IDs (same as page IDs) for article, top-level section, and hierarchical section retrieval.</p>
</dd>
</dl>
<h4 id="evaluation.">Evaluation.</h4>
<p>We recommend to use the retrieval evaluation tool <code>trec-eval</code>[^10] with option <code>-c</code> using the provided qrels files.</p>
<figure>
<img src="entity-linking-benchmark.png" alt="Wikimarks derived for query-specific entity linking (bottom) from a the second paragraph (top). The task is to annotate the plain text with entity links (for example with entities a, d, and e). True entities d and e are derived from hyperlinks contained in this paragraph (bold) with given character spans. Since entity a was linked in a previous paragraph and its annotation is to be accepted without penalty." /><figcaption aria-hidden="true"><em>Wikimarks</em> derived for query-specific entity linking (bottom) from a the second paragraph (top). The task is to annotate the plain text with entity links (for example with entities a, d, and e). True entities d and e are derived from hyperlinks contained in this paragraph (bold) with given character spans. Since entity a was linked in a previous paragraph and its annotation is to be accepted without penalty.</figcaption>
</figure>
<h2 id="sec:wikimark">Query-specific Clustering <em>Wikimark</em></h2>
<p>The task of search result clustering, will, given a search query and a ranking of search results, identify query-specific clusters for presentation. We provide a <em>Wikimark</em> dataset for this clustering task, where the query is taken as page title, and each top-level section defines one ground truth cluster. The search results are taken from the article-level retrieval task. To train on this task in isolation from a retrieval system, we suggest to use all passages that originate from this page.</p>
<p>The query-specific clustering <em>Wikimark</em> is provided as a JSONL gzipped file[^11] which contains the following information:</p>
<dl>
<dt>Query:</dt>
<dd><p>The query text is derived from the page name; the query ID from the page ID.</p>
</dd>
<dt>Elements:</dt>
<dd><p>List of paragraph IDs contained on the page.</p>
</dd>
<dt>True Cluster Labels <span class="math inline">†</span>:</dt>
<dd><p>List of true cluster labels for each element. The <span class="math inline"><em>i</em></span>’th cluster label is derived from the section ID of the top-level section where the <span class="math inline"><em>i</em></span>’th element is located.</p>
</dd>
<dt>True Cluster Index <span class="math inline">†</span>:</dt>
<dd><p>Projecting the true cluster labels onto integers from <span class="math inline">0, 1…</span>.</p>
</dd>
</dl>
<p>In this <em>Wikimark</em>, we remove instances with less than two clusters.</p>
<p>Number of train/test instances for each Wikimark.</p>
<div class="table*">
<div class="footnotesize">
<table>
<tbody>
<tr class="odd">
<td></td>
<td style="text-align: right;">Relevant Passages</td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;">Relevant Entities</td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;">Clustering Instances</td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;">Entity Linking Instances</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td style="text-align: right;">en</td>
<td>simple</td>
<td>ja</td>
<td></td>
<td style="text-align: right;">en</td>
<td>simple</td>
<td>ja</td>
<td></td>
<td style="text-align: right;">en</td>
<td>simple</td>
<td>ja</td>
<td></td>
<td style="text-align: right;">en</td>
<td>simple</td>
<td>jp</td>
<td></td>
</tr>
<tr class="odd">
<td>vital-articles.test</td>
<td style="text-align: right;">44,444</td>
<td>7,117</td>
<td>12,448</td>
<td></td>
<td style="text-align: right;">159,392</td>
<td>20,626</td>
<td>38,975</td>
<td></td>
<td style="text-align: right;">521</td>
<td>328</td>
<td>393</td>
<td></td>
<td style="text-align: right;">64,857</td>
<td>9,339</td>
<td>23,217</td>
<td></td>
</tr>
<tr class="even">
<td>vital-articles.train</td>
<td style="text-align: right;">42,008</td>
<td>6,845</td>
<td>13,330</td>
<td></td>
<td style="text-align: right;">149,609</td>
<td>19,401</td>
<td>42,357</td>
<td></td>
<td style="text-align: right;">528</td>
<td>324</td>
<td>440</td>
<td></td>
<td style="text-align: right;">61,984</td>
<td>8,663</td>
<td>25,743</td>
<td></td>
</tr>
<tr class="odd">
<td>good-articles.test</td>
<td style="text-align: right;">408,454</td>
<td>7</td>
<td>23,869</td>
<td></td>
<td style="text-align: right;">1429,087</td>
<td>47</td>
<td>65,031</td>
<td></td>
<td style="text-align: right;">17,088</td>
<td>1</td>
<td>626</td>
<td></td>
<td style="text-align: right;">777,081</td>
<td>8</td>
<td>27,903</td>
<td></td>
</tr>
<tr class="even">
<td>good-articles.train</td>
<td style="text-align: right;">415,034</td>
<td>17</td>
<td>24,375</td>
<td></td>
<td style="text-align: right;">1465,327</td>
<td>87</td>
<td>61,050</td>
<td></td>
<td style="text-align: right;">17,362</td>
<td>1</td>
<td>626</td>
<td></td>
<td style="text-align: right;">789,726</td>
<td>39</td>
<td>27,538</td>
<td></td>
</tr>
<tr class="odd">
<td>US-history.test</td>
<td style="text-align: right;">83,213</td>
<td>176</td>
<td>–</td>
<td></td>
<td style="text-align: right;">206,672</td>
<td>405</td>
<td>–</td>
<td></td>
<td style="text-align: right;">4,232</td>
<td>6</td>
<td>–</td>
<td></td>
<td style="text-align: right;">169,014</td>
<td>210</td>
<td>–</td>
<td></td>
</tr>
<tr class="even">
<td>US-history.train</td>
<td style="text-align: right;">83,255</td>
<td>146</td>
<td>–</td>
<td></td>
<td style="text-align: right;">205,438</td>
<td>608</td>
<td>–</td>
<td></td>
<td style="text-align: right;">4,285</td>
<td>7</td>
<td>–</td>
<td></td>
<td style="text-align: right;">160,764</td>
<td>173</td>
<td>–</td>
<td></td>
</tr>
<tr class="odd">
<td>horseshoe-crab.train</td>
<td style="text-align: right;">21</td>
<td>11</td>
<td>–</td>
<td></td>
<td style="text-align: right;">69</td>
<td>40</td>
<td>–</td>
<td></td>
<td style="text-align: right;">1</td>
<td>1</td>
<td>–</td>
<td></td>
<td style="text-align: right;">44</td>
<td>13</td>
<td>–</td>
<td></td>
</tr>
<tr class="even">
<td>benchmarkY1.test</td>
<td style="text-align: right;">6,554</td>
<td>434</td>
<td>1,160</td>
<td></td>
<td style="text-align: right;">15,698</td>
<td>1,117</td>
<td>3,018</td>
<td></td>
<td style="text-align: right;">131</td>
<td>23</td>
<td>56</td>
<td></td>
<td style="text-align: right;">8,536</td>
<td>454</td>
<td>1,978</td>
<td></td>
</tr>
<tr class="odd">
<td>benchmarkY1.train</td>
<td style="text-align: right;">5,588</td>
<td>449</td>
<td>1,396</td>
<td></td>
<td style="text-align: right;">14,744</td>
<td>1,273</td>
<td>3,440</td>
<td></td>
<td style="text-align: right;">117</td>
<td>25</td>
<td>60</td>
<td></td>
<td style="text-align: right;">7,258</td>
<td>513</td>
<td>2,152</td>
<td></td>
</tr>
<tr class="even">
<td>car-train-large.train</td>
<td style="text-align: right;">9,254,925</td>
<td>113,444</td>
<td>1496,289</td>
<td></td>
<td style="text-align: right;">19,764,159</td>
<td>249,369</td>
<td>3,462,123</td>
<td></td>
<td style="text-align: right;">885,014</td>
<td>6,918</td>
<td>87,012</td>
<td></td>
<td style="text-align: right;">25,423,934</td>
<td>185,203</td>
<td>3824,333</td>
<td></td>
</tr>
<tr class="odd">
<td>test200.train</td>
<td style="text-align: right;">5,537</td>
<td>109</td>
<td>335</td>
<td></td>
<td style="text-align: right;">12,345</td>
<td>272</td>
<td>929</td>
<td></td>
<td style="text-align: right;">188</td>
<td>5</td>
<td>19</td>
<td></td>
<td style="text-align: right;">9,147</td>
<td>135</td>
<td>612</td>
<td></td>
</tr>
</tbody>
</table>
</div>
</div>
<h2 id="evaluation-results-for-reference-baselines">Evaluation Results for Reference Baselines</h2>
<div class="table*">
<table>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td style="text-align: right;">simple</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;">en</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td style="text-align: right;">benchmarkY1.train</td>
<td></td>
<td></td>
<td></td>
<td>benchmarkY1.test</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;">benchmarkY1.train</td>
<td></td>
<td></td>
<td></td>
<td>benchmarkY1.test</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>Paragraph Retrieval [MAP]</td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>bm25</td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>31</strong></td>
<td><strong>0</strong></td>
<td><strong>04</strong></td>
<td><strong>0</strong></td>
<td><strong>29</strong></td>
<td><strong>0</strong></td>
<td><strong>03</strong></td>
<td></td>
<td></td>
<td style="text-align: right;">0</td>
<td>+/-097</td>
<td></td>
<td>0 +/-01</td>
<td></td>
<td>0 +/-0</td>
<td>94</td>
<td>0 +/-01</td>
</tr>
<tr class="odd">
<td>bm25-rm3</td>
<td></td>
<td style="text-align: right;">0</td>
<td>29</td>
<td>0</td>
<td>04</td>
<td>0</td>
<td>26</td>
<td>0</td>
<td>03</td>
<td></td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>107</strong></td>
<td><strong>0</strong></td>
<td><strong>01</strong></td>
<td><strong>0</strong></td>
<td><strong>101</strong></td>
<td><strong>0</strong></td>
<td><strong>01</strong></td>
</tr>
<tr class="even">
<td>QL-rm3</td>
<td></td>
<td style="text-align: right;">0</td>
<td>25</td>
<td>0</td>
<td>04</td>
<td>0</td>
<td>20</td>
<td>0</td>
<td>02</td>
<td></td>
<td></td>
<td style="text-align: right;">0</td>
<td>084</td>
<td>0</td>
<td>01</td>
<td>0</td>
<td>076</td>
<td>0</td>
<td>01</td>
</tr>
<tr class="odd">
<td>Entity Ranking [MAP]</td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>page-bm25</td>
<td></td>
<td style="text-align: right;">0</td>
<td>03</td>
<td>0</td>
<td>005</td>
<td>0</td>
<td>038</td>
<td>0</td>
<td>007</td>
<td></td>
<td></td>
<td style="text-align: right;">0</td>
<td>025</td>
<td>0</td>
<td>002</td>
<td>0</td>
<td>026</td>
<td>0</td>
<td>003</td>
</tr>
<tr class="odd">
<td>page-bm25-rm3</td>
<td></td>
<td style="text-align: right;">0</td>
<td>05</td>
<td>0</td>
<td>007</td>
<td>0</td>
<td>048</td>
<td>0</td>
<td>007</td>
<td></td>
<td></td>
<td style="text-align: right;">0</td>
<td>037</td>
<td>0</td>
<td>003</td>
<td>0</td>
<td>038</td>
<td>0</td>
<td>004</td>
</tr>
<tr class="even">
<td>paragraph-bm25-ECM</td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>23</strong></td>
<td><strong>0</strong></td>
<td><strong>03</strong></td>
<td><strong>0</strong></td>
<td><strong>253</strong></td>
<td><strong>0</strong></td>
<td><strong>021</strong></td>
<td></td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>215</strong></td>
<td><strong>0</strong></td>
<td><strong>01</strong></td>
<td><strong>0</strong></td>
<td><strong>21</strong></td>
<td><strong>0</strong></td>
<td><strong>01</strong></td>
</tr>
<tr class="odd">
<td>Cluster [Adjusted RAND Index]</td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>TF-IDF agglomerative</td>
<td></td>
<td style="text-align: right;">0</td>
<td>16</td>
<td>0</td>
<td>06</td>
<td>0</td>
<td>27</td>
<td>0</td>
<td>07</td>
<td></td>
<td></td>
<td style="text-align: right;">0</td>
<td>15</td>
<td>0</td>
<td>01</td>
<td>0</td>
<td>16</td>
<td>0</td>
<td>01</td>
</tr>
<tr class="odd">
<td>TF-IDF kmeans</td>
<td></td>
<td style="text-align: right;">0</td>
<td>13</td>
<td>0</td>
<td>01</td>
<td>0</td>
<td>12</td>
<td>0</td>
<td>01</td>
<td></td>
<td></td>
<td style="text-align: right;">0</td>
<td>11</td>
<td>0</td>
<td>04</td>
<td><strong>0</strong></td>
<td><strong>19</strong></td>
<td><strong>0</strong></td>
<td><strong>05</strong></td>
</tr>
<tr class="even">
<td>SBERT kmeans</td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>38</strong></td>
<td><strong>0</strong></td>
<td><strong>09</strong></td>
<td><strong>0</strong></td>
<td><strong>38</strong></td>
<td><strong>0</strong></td>
<td><strong>09</strong></td>
<td></td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>23</strong></td>
<td><strong>0</strong></td>
<td><strong>02</strong></td>
<td><strong>0</strong></td>
<td><strong>19</strong></td>
<td><strong>0</strong></td>
<td><strong>01</strong></td>
</tr>
<tr class="odd">
<td>Entity Linking [Paragraph-Macro-avg F1]</td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td style="text-align: right;"></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>WAT</td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>44</strong></td>
<td><strong>0</strong></td>
<td><strong>01</strong></td>
<td><strong>0</strong></td>
<td><strong>42</strong></td>
<td><strong>0</strong></td>
<td><strong>01</strong></td>
<td></td>
<td></td>
<td style="text-align: right;"><strong>0</strong></td>
<td><strong>332</strong></td>
<td><strong>0</strong></td>
<td><strong>004</strong></td>
<td><strong>0</strong></td>
<td><strong>310</strong></td>
<td><strong>0</strong></td>
<td><strong>003</strong></td>
</tr>
</tbody>
</table>
</div>
<h2 id="license">License</h2>
<p>The conversions and benchmarks described above are licensed under the <a href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution-ShareAlike 3.0 Unported License</a>.</p>
        </section>
      </div>
    </div>
  </body>
</html>

